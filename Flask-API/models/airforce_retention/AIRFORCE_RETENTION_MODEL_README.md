# Air Force Retention Prediction Model
The test data and model in this folder was generated by Claude Code.

## Overview
This machine learning model predicts whether an Air Force service member will be retained based on various demographic, career, and compensation factors.

## Model Performance

### Best Model: Logistic Regression
- **Accuracy**: 92.50%
- **Precision**: 95.21%
- **Recall**: 95.78%
- **F1 Score**: 95.50%
- **ROC-AUC**: 97.52%

### Cross-Validation Performance
- **Mean F1 Score**: 94.13% (+/- 1.06%)

### Confusion Matrix (Test Set)
- True Positives (Correctly predicted retained): 159
- True Negatives (Correctly predicted not retained): 26
- False Positives: 8
- False Negatives: 7

## Dataset
- **Source**: `datasets/airforce_retention_data.csv`
- **Total Records**: 1,000
- **Training Set**: 800 samples (80%)
- **Test Set**: 200 samples (20%)
- **Target Distribution**: 82.9% retained, 17.1% not retained

## Features Used

The model uses 9 features to make predictions:

1. **age**: Age of the service member
2. **gender_encoded**: Gender (Male/Female)
3. **marital_status_encoded**: Marital status (Married/Single)
4. **num_dependents**: Number of dependents
5. **rank_level**: Rank level extracted from grade (E-1 to E-9)
6. **salary**: Annual salary
7. **years_of_service**: Total years in service
8. **num_prior_reenlistments**: Number of previous reenlistments
9. **bonuses_received**: Total retention bonuses received

### Categorical Encodings

**Gender:**
- Female → 0
- Male → 1

**Marital Status:**
- Married → 0
- Single → 1

**Grade/Rank:**
- E-1 (AB) → 0
- E-2 (Amn) → 1
- E-3 (A1C) → 2
- E-4 (SrA) → 3
- E-5 (SSgt) → 4
- E-6 (TSgt) → 5
- E-7 (MSgt) → 6
- E-8 (SMSgt) → 7
- E-9 (CMSgt) → 8

## Files

### Training Script
- **File**: `train_airforce_retention_model.py`
- **Purpose**: Trains multiple models, performs hyperparameter tuning, and saves the best model
- **Usage**: `python train_airforce_retention_model.py`

### Prediction Script
- **File**: `predict_airforce_retention.py`
- **Purpose**: Demonstrates how to load and use the trained model for predictions
- **Usage**: `python predict_airforce_retention.py`

### Model Artifacts (in `models/` directory)
1. **airforce_retention_model.pkl**: Trained Logistic Regression model
2. **airforce_retention_scaler.pkl**: StandardScaler for feature normalization
3. **airforce_retention_encoders.pkl**: Label encoders for categorical variables
4. **airforce_retention_feature_info.pkl**: Feature metadata and model configuration

## Usage Example

```python
import pandas as pd
import joblib

# Load model artifacts
model = joblib.load('models/airforce_retention_model.pkl')
scaler = joblib.load('models/airforce_retention_scaler.pkl')
encoders = joblib.load('models/airforce_retention_encoders.pkl')
feature_info = joblib.load('models/airforce_retention_feature_info.pkl')

# Prepare input data
airman_data = {
    'age': 28,
    'gender': 'Male',
    'marital_status': 'Married',
    'num_dependents': 2,
    'grade_rank': 'E-6 (TSgt)',
    'salary': 47000,
    'years_of_service': 10,
    'num_prior_reenlistments': 2,
    'bonuses_received': 10000
}

# Create DataFrame
df = pd.DataFrame([airman_data])

# Encode categorical variables
for col in ['gender', 'marital_status', 'grade_rank']:
    df[col + '_encoded'] = encoders[col].transform(df[col])

# Extract rank level
df['rank_level'] = df['grade_rank'].str.extract(r'E-(\d+)').astype(int)

# Select features
features = df[feature_info['feature_columns']]

# Scale features (Logistic Regression requires scaling)
features_scaled = scaler.transform(features)

# Make prediction
prediction = model.predict(features_scaled)[0]
probability = model.predict_proba(features_scaled)[0]

print(f"Retained: {prediction}")
print(f"Retention probability: {probability[1]:.2%}")
```

## Model Insights

### Key Predictors of Retention
Based on the Logistic Regression model, the most important factors for retention include:
- Years of service
- Number of prior reenlistments
- Rank level
- Bonuses received
- Age
- Marital status

### Retention Patterns
- **High Retention**: Senior NCOs (E-7 and above), married, multiple reenlistments, bonus recipients
- **Lower Retention**: Junior enlisted (E-1 to E-4), single, first term, no bonuses
- **Mid-Career**: E-5 and E-6 with 8-12 years of service show strong retention when married with dependents

## Model Comparison

Three models were trained and compared:

| Model | Accuracy | Precision | Recall | F1 Score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| Logistic Regression | 92.50% | 95.21% | 95.78% | **95.50%** | **97.52%** |
| Random Forest | 90.50% | 94.01% | 94.58% | 94.29% | 96.04% |
| Gradient Boosting | 90.50% | 94.01% | 94.58% | 94.29% | 95.89% |

Logistic Regression was selected as the best model due to its superior F1 score and ROC-AUC performance.

## Dependencies

Required Python packages:
- pandas
- numpy
- scikit-learn
- joblib

Install with:
```bash
pip install pandas numpy scikit-learn joblib
```

## Future Improvements

Potential enhancements to consider:
1. Collect additional features (deployment history, job satisfaction scores, education level)
2. Implement ensemble methods combining multiple models
3. Add time-series analysis for retention trends over time
4. Develop separate models for different career fields (MOS-specific)
5. Incorporate external factors (economy, military policy changes)
6. Build a web API endpoint for real-time predictions
7. Create visualization dashboards for retention analytics

## Notes

- The model uses synthetic data for demonstration purposes
- Feature scaling is required for the Logistic Regression model
- The model assumes input data follows the same format as training data
- Regular retraining is recommended as new data becomes available
- Consider class imbalance (83% retained vs 17% not retained) when interpreting results

## Contact

For questions or issues, please refer to the project documentation or contact the development team.
